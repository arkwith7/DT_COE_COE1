{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import shutil \n",
    "\n",
    "alist=os.listdir('train')\n",
    "\n",
    "\n",
    "for i in alist:\n",
    "    if len(i)-4==5:\n",
    "        shutil.move('train/'+i, 'train_proc/'+i[:-4]+'XX'+'.png')\n",
    "    elif len(i)-4==6:\n",
    "        shutil.move('train/'+i, 'train_proc/'+i[:-4]+'X'+'.png')\n",
    "    elif len(i)-4==8:\n",
    "        shutil.move('train/'+i, 'train_proc/'+i[:-5]+'.png')\n",
    "    elif len(i)-4==7:\n",
    "        shutil.move('train/'+i, 'train_proc/'+i[:-4]+'.png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['226md.png',\n",
       " '22d5n.png',\n",
       " '2356g.png',\n",
       " '23mdg.png',\n",
       " '23n88.png',\n",
       " '243mm.png',\n",
       " '244e2.png',\n",
       " '245y5.png',\n",
       " '24f6w.png',\n",
       " '24pew.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "DIR = 'captcha-version-2-images/samples'\n",
    "path = Path(DIR)\n",
    "os.listdir(path)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#labels = [[char for char in code.name[:-4]] for code in (path).glob('*.png')]\n",
    "#labels = set([letter for label in labels for letter in label])\n",
    "#print(len(labels), 'different labels were found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[char for char in code.name[:-4]] for code in (path).glob('*.png')]\n",
    "labels = set([letter for label in labels for letter in label])\n",
    "labels=list(labels)\n",
    "labels.sort()\n",
    "print(len(labels), 'different labels were found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_dict = {l:e for e,l in enumerate(labels)}\n",
    "decoding_dict = {e:l for l,e in encoding_dict.items()}\n",
    "\n",
    "code_dimension = len(labels)\n",
    "captcha_dimension = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_onehot(filename):\n",
    "    code = filename.name[:-4]\n",
    "    onehot = np.zeros((code_dimension, captcha_dimension))\n",
    "    for column, letter in enumerate(code):\n",
    "        onehot[encoding_dict[letter], column] = 1\n",
    "    return onehot.reshape(-1)\n",
    "\n",
    "def to_idx(filename):\n",
    "    code = filename.name[:-4]\n",
    "    return np.array([encoding_dict[c] for c in code])#, dtype=torch.long)\n",
    "\n",
    "def decode(onehot):\n",
    "    onehot = onehot.reshape(code_dimension, captcha_dimension)\n",
    "    idx = np.argmax(onehot, axis=0)\n",
    "    return [decoding_dict[i.item()] for i in idx]\n",
    "\n",
    "def label_accuracy(preds, actuals):\n",
    "    pred = torch.unbind(preds)\n",
    "    act = torch.unbind(actuals)\n",
    "    \n",
    "    valid = 0\n",
    "    total = 0\n",
    "    \n",
    "    for left,right in zip(pred,act):\n",
    "        total+=1\n",
    "        p = decode(left)\n",
    "        a = decode(right)\n",
    "        if p==a: valid += 1\n",
    "\n",
    "    return torch.tensor(valid/total).cuda()\n",
    "\n",
    "def char_accuracy(n):\n",
    "    def c_acc(preds, actuals):\n",
    "        pred = torch.unbind(preds)\n",
    "        act = torch.unbind(actuals)\n",
    "\n",
    "        valid = 0\n",
    "        total = 0\n",
    "\n",
    "        for left,right in zip(pred,act):\n",
    "            total+=1\n",
    "            p = decode(left)\n",
    "            a = decode(right)\n",
    "            if p[n]==a[n]: valid += 1\n",
    "\n",
    "        return torch.tensor(valid/total).cuda()\n",
    "    return c_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_folder(path)\n",
    "        .split_by_rand_pct(0.2,42)\n",
    "        .label_from_func(to_onehot, label_cls = FloatList) #making it a regression instead of classification (because this gave better results)\n",
    "        .transform(size=(77,247))\n",
    "        .databunch(bs=64))\n",
    "        #.normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.batchsize=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(7,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=Path('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet50, model_dir='models',pretrained=False,path=Path(''),\n",
    "                    metrics=[label_accuracy, char_accuracy(0),char_accuracy(1),char_accuracy(2),char_accuracy(3),char_accuracy(4),char_accuracy(5),char_accuracy(6)],\n",
    "                   ps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next cell showed an error. https://forums.fast.ai/t/lesson-2-amazon-planet-cant-create-numpy-are-from-cuda-tensor/28380/7\n",
    "\n",
    "# Got away with it by : \n",
    "# I went to the fastai code in the last file mentioned in the error(tensor.py) and replaced self.numpy() with self.cpu().numpy(). Your calls will automatically access this change.\n",
    "\n",
    "# /home/sarwari/anaconda/envs/fastai/lib/python3.6/site-packages/torch/tensor.py This file was changed.\n",
    "\n",
    "'''Changed \n",
    "def __array__(self, dtype=None):\n",
    "        if dtype is None:\n",
    "            return self.numpy()\n",
    "        else:\n",
    "            return self.numpy().astype(dtype, copy=False)\n",
    "            \n",
    "To\n",
    "\n",
    "def __array__(self, dtype=None):\n",
    "        if dtype is None:\n",
    "            return self.cpu().numpy()\n",
    "        else:\n",
    "            return self.cpu().numpy().astype(dtype, copy=False)\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "lr=5e-3\n",
    "learn.fit_one_cycle(70,max_lr=lr,wd=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learn.save('stage-1',return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('stage-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image('test/ablger.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "pred_class,pred_idx,outputs = learn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image('test/caning.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "pred_class,pred_idx,outputs = learn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
