{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "ALL_CHAR_SET = NUMBER + ALPHABET\n",
    "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
    "MAX_CAPTCHA = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(a):\n",
    "    onehot = [0]*ALL_CHAR_SET_LEN\n",
    "    idx = ALL_CHAR_SET.index(a)\n",
    "    onehot[idx] += 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self, path, is_train=True, transform=None):\n",
    "        self.path = path\n",
    "        if is_train: self.img = os.listdir(self.path)[:1000]\n",
    "        else: self.img = os.listdir(self.path)[1001:]\n",
    "        try: self.img.remove('3bnfnd.png')\n",
    "        except: pass\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img[idx]\n",
    "        img = Image.open(self.path/img_path)\n",
    "        img = img.convert('L')\n",
    "        label = Path(self.path/img_path).name[:-4]\n",
    "        label_oh = []\n",
    "        for i in label:\n",
    "            label_oh += encode(i)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, np.array(label_oh), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ds = Mydataset(Path('captcha-version-2-images/samples/samples'), transform=transform)\n",
    "test_ds = Mydataset(Path('captcha-version-2-images/samples/samples'), False, transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=64, num_workers=0)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=ALL_CHAR_SET_LEN*MAX_CAPTCHA, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "optm = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 1 step: 1 loss: 0.699721097946167\n",
      "eopch: 1 step: 2 loss: 0.4976096749305725\n",
      "eopch: 1 step: 3 loss: 0.33146166801452637\n",
      "eopch: 1 step: 4 loss: 0.22709867358207703\n",
      "eopch: 1 step: 5 loss: 0.1722574532032013\n",
      "eopch: 1 step: 6 loss: 0.14704519510269165\n",
      "eopch: 1 step: 7 loss: 0.13508272171020508\n",
      "eopch: 1 step: 8 loss: 0.1305321902036667\n",
      "eopch: 1 step: 9 loss: 0.12763851881027222\n",
      "eopch: 1 step: 10 loss: 0.1288197785615921\n",
      "eopch: 1 step: 11 loss: 0.13337406516075134\n",
      "eopch: 1 step: 12 loss: 0.13591766357421875\n",
      "eopch: 1 step: 13 loss: 0.13892564177513123\n",
      "eopch: 1 step: 14 loss: 0.13189545273780823\n",
      "eopch: 1 step: 15 loss: 0.13050614297389984\n",
      "eopch: 1 step: 16 loss: 0.13151024281978607\n",
      "eopch: 2 step: 1 loss: 0.12486008554697037\n",
      "eopch: 2 step: 2 loss: 0.12422467768192291\n",
      "eopch: 2 step: 3 loss: 0.1222267746925354\n",
      "eopch: 2 step: 4 loss: 0.11861170828342438\n",
      "eopch: 2 step: 5 loss: 0.11507734656333923\n",
      "eopch: 2 step: 6 loss: 0.1122274324297905\n",
      "eopch: 2 step: 7 loss: 0.11126325279474258\n",
      "eopch: 2 step: 8 loss: 0.10982733964920044\n",
      "eopch: 2 step: 9 loss: 0.1100420355796814\n",
      "eopch: 2 step: 10 loss: 0.11118131130933762\n",
      "eopch: 2 step: 11 loss: 0.11194925010204315\n",
      "eopch: 2 step: 12 loss: 0.1114358901977539\n",
      "eopch: 2 step: 13 loss: 0.10891774296760559\n",
      "eopch: 2 step: 14 loss: 0.10862161219120026\n",
      "eopch: 2 step: 15 loss: 0.11367945373058319\n",
      "eopch: 2 step: 16 loss: 0.11206959933042526\n",
      "eopch: 3 step: 1 loss: 0.11412473022937775\n",
      "eopch: 3 step: 2 loss: 0.11350483447313309\n",
      "eopch: 3 step: 3 loss: 0.11251500248908997\n",
      "eopch: 3 step: 4 loss: 0.11060388386249542\n",
      "eopch: 3 step: 5 loss: 0.11163540184497833\n",
      "eopch: 3 step: 6 loss: 0.11060203611850739\n",
      "eopch: 3 step: 7 loss: 0.10989898443222046\n",
      "eopch: 3 step: 8 loss: 0.10867324471473694\n",
      "eopch: 3 step: 9 loss: 0.10904590040445328\n",
      "eopch: 3 step: 10 loss: 0.10899670422077179\n",
      "eopch: 3 step: 11 loss: 0.10899429023265839\n",
      "eopch: 3 step: 12 loss: 0.10907691717147827\n",
      "eopch: 3 step: 13 loss: 0.10585792362689972\n",
      "eopch: 3 step: 14 loss: 0.10635308176279068\n",
      "eopch: 3 step: 15 loss: 0.10997946560382843\n",
      "eopch: 3 step: 16 loss: 0.10711470991373062\n",
      "eopch: 4 step: 1 loss: 0.10930502414703369\n",
      "eopch: 4 step: 2 loss: 0.1081015020608902\n",
      "eopch: 4 step: 3 loss: 0.10803648829460144\n",
      "eopch: 4 step: 4 loss: 0.10704467445611954\n",
      "eopch: 4 step: 5 loss: 0.10897880792617798\n",
      "eopch: 4 step: 6 loss: 0.10787814110517502\n",
      "eopch: 4 step: 7 loss: 0.10749253630638123\n",
      "eopch: 4 step: 8 loss: 0.10724461078643799\n",
      "eopch: 4 step: 9 loss: 0.10790377855300903\n",
      "eopch: 4 step: 10 loss: 0.10735964775085449\n",
      "eopch: 4 step: 11 loss: 0.10726000368595123\n",
      "eopch: 4 step: 12 loss: 0.10779742896556854\n",
      "eopch: 4 step: 13 loss: 0.10625030100345612\n",
      "eopch: 4 step: 14 loss: 0.10540066659450531\n",
      "eopch: 4 step: 15 loss: 0.10846872627735138\n",
      "eopch: 4 step: 16 loss: 0.10572190582752228\n",
      "eopch: 5 step: 1 loss: 0.10724317282438278\n",
      "eopch: 5 step: 2 loss: 0.10723717510700226\n",
      "eopch: 5 step: 3 loss: 0.10700578987598419\n",
      "eopch: 5 step: 4 loss: 0.10569459199905396\n",
      "eopch: 5 step: 5 loss: 0.10780839622020721\n",
      "eopch: 5 step: 6 loss: 0.10625017434358597\n",
      "eopch: 5 step: 7 loss: 0.10564431548118591\n",
      "eopch: 5 step: 8 loss: 0.10520067065954208\n",
      "eopch: 5 step: 9 loss: 0.10615122318267822\n",
      "eopch: 5 step: 10 loss: 0.10582007467746735\n",
      "eopch: 5 step: 11 loss: 0.10568338632583618\n",
      "eopch: 5 step: 12 loss: 0.10649707168340683\n",
      "eopch: 5 step: 13 loss: 0.10417047142982483\n",
      "eopch: 5 step: 14 loss: 0.10377079993486404\n",
      "eopch: 5 step: 15 loss: 0.10739977657794952\n",
      "eopch: 5 step: 16 loss: 0.10458586364984512\n",
      "eopch: 6 step: 1 loss: 0.10580694675445557\n",
      "eopch: 6 step: 2 loss: 0.10592376440763474\n",
      "eopch: 6 step: 3 loss: 0.10550450533628464\n",
      "eopch: 6 step: 4 loss: 0.10419712960720062\n",
      "eopch: 6 step: 5 loss: 0.10630127787590027\n",
      "eopch: 6 step: 6 loss: 0.10477682948112488\n",
      "eopch: 6 step: 7 loss: 0.10394149273633957\n",
      "eopch: 6 step: 8 loss: 0.10352606326341629\n",
      "eopch: 6 step: 9 loss: 0.10442911088466644\n",
      "eopch: 6 step: 10 loss: 0.10403774678707123\n",
      "eopch: 6 step: 11 loss: 0.10374319553375244\n",
      "eopch: 6 step: 12 loss: 0.10536031424999237\n",
      "eopch: 6 step: 13 loss: 0.1026030033826828\n",
      "eopch: 6 step: 14 loss: 0.10169139504432678\n",
      "eopch: 6 step: 15 loss: 0.10606684535741806\n",
      "eopch: 6 step: 16 loss: 0.1025817021727562\n",
      "eopch: 7 step: 1 loss: 0.10386521369218826\n",
      "eopch: 7 step: 2 loss: 0.10358904302120209\n",
      "eopch: 7 step: 3 loss: 0.10297549515962601\n",
      "eopch: 7 step: 4 loss: 0.10193483531475067\n",
      "eopch: 7 step: 5 loss: 0.10409880429506302\n",
      "eopch: 7 step: 6 loss: 0.10284923017024994\n",
      "eopch: 7 step: 7 loss: 0.10151644796133041\n",
      "eopch: 7 step: 8 loss: 0.10110528767108917\n",
      "eopch: 7 step: 9 loss: 0.10183507204055786\n",
      "eopch: 7 step: 10 loss: 0.10148662328720093\n",
      "eopch: 7 step: 11 loss: 0.10117922723293304\n",
      "eopch: 7 step: 12 loss: 0.10308188199996948\n",
      "eopch: 7 step: 13 loss: 0.10014531016349792\n",
      "eopch: 7 step: 14 loss: 0.09864276647567749\n",
      "eopch: 7 step: 15 loss: 0.10380686074495316\n",
      "eopch: 7 step: 16 loss: 0.09912645071744919\n",
      "eopch: 8 step: 1 loss: 0.10023722052574158\n",
      "eopch: 8 step: 2 loss: 0.09996694326400757\n",
      "eopch: 8 step: 3 loss: 0.09981689602136612\n",
      "eopch: 8 step: 4 loss: 0.0980730950832367\n",
      "eopch: 8 step: 5 loss: 0.10095034539699554\n",
      "eopch: 8 step: 6 loss: 0.09865743666887283\n",
      "eopch: 8 step: 7 loss: 0.09761403501033783\n",
      "eopch: 8 step: 8 loss: 0.09667917340993881\n",
      "eopch: 8 step: 9 loss: 0.09717857837677002\n",
      "eopch: 8 step: 10 loss: 0.09786266088485718\n",
      "eopch: 8 step: 11 loss: 0.09669174998998642\n",
      "eopch: 8 step: 12 loss: 0.10029307007789612\n",
      "eopch: 8 step: 13 loss: 0.09593578428030014\n",
      "eopch: 8 step: 14 loss: 0.09371422231197357\n",
      "eopch: 8 step: 15 loss: 0.10071679204702377\n",
      "eopch: 8 step: 16 loss: 0.09483643621206284\n",
      "eopch: 9 step: 1 loss: 0.09598146378993988\n",
      "eopch: 9 step: 2 loss: 0.09520825743675232\n",
      "eopch: 9 step: 3 loss: 0.09502387791872025\n",
      "eopch: 9 step: 4 loss: 0.09334106743335724\n",
      "eopch: 9 step: 5 loss: 0.09689578413963318\n",
      "eopch: 9 step: 6 loss: 0.09364457428455353\n",
      "eopch: 9 step: 7 loss: 0.09312064200639725\n",
      "eopch: 9 step: 8 loss: 0.09151880443096161\n",
      "eopch: 9 step: 9 loss: 0.09228592365980148\n",
      "eopch: 9 step: 10 loss: 0.09325537085533142\n",
      "eopch: 9 step: 11 loss: 0.09183262288570404\n",
      "eopch: 9 step: 12 loss: 0.09698335081338882\n",
      "eopch: 9 step: 13 loss: 0.09112268686294556\n",
      "eopch: 9 step: 14 loss: 0.08827821165323257\n",
      "eopch: 9 step: 15 loss: 0.09731511026620865\n",
      "eopch: 9 step: 16 loss: 0.08937539905309677\n",
      "eopch: 10 step: 1 loss: 0.09089212864637375\n",
      "eopch: 10 step: 2 loss: 0.09029127657413483\n",
      "eopch: 10 step: 3 loss: 0.0895557701587677\n",
      "eopch: 10 step: 4 loss: 0.08796928822994232\n",
      "eopch: 10 step: 5 loss: 0.09218788892030716\n",
      "eopch: 10 step: 6 loss: 0.08850938081741333\n",
      "eopch: 10 step: 7 loss: 0.08768285810947418\n",
      "eopch: 10 step: 8 loss: 0.0856538787484169\n",
      "eopch: 10 step: 9 loss: 0.08635155856609344\n",
      "eopch: 10 step: 10 loss: 0.08835545182228088\n",
      "eopch: 10 step: 11 loss: 0.08637882769107819\n",
      "eopch: 10 step: 12 loss: 0.09310789406299591\n",
      "eopch: 10 step: 13 loss: 0.08589311689138412\n",
      "eopch: 10 step: 14 loss: 0.08283267170190811\n",
      "eopch: 10 step: 15 loss: 0.0924597978591919\n",
      "eopch: 10 step: 16 loss: 0.08362855762243271\n",
      "eopch: 11 step: 1 loss: 0.08587333559989929\n",
      "eopch: 11 step: 2 loss: 0.08567080646753311\n",
      "eopch: 11 step: 3 loss: 0.08406124264001846\n",
      "eopch: 11 step: 4 loss: 0.08277585357427597\n",
      "eopch: 11 step: 5 loss: 0.08724798262119293\n",
      "eopch: 11 step: 6 loss: 0.08318697661161423\n",
      "eopch: 11 step: 7 loss: 0.08279919624328613\n",
      "eopch: 11 step: 8 loss: 0.079827219247818\n",
      "eopch: 11 step: 9 loss: 0.08047129213809967\n",
      "eopch: 11 step: 10 loss: 0.08375968039035797\n",
      "eopch: 11 step: 11 loss: 0.08070338517427444\n",
      "eopch: 11 step: 12 loss: 0.08877034485340118\n",
      "eopch: 11 step: 13 loss: 0.08072012662887573\n",
      "eopch: 11 step: 14 loss: 0.07799826562404633\n",
      "eopch: 11 step: 15 loss: 0.08688226342201233\n",
      "eopch: 11 step: 16 loss: 0.07759503275156021\n",
      "eopch: 12 step: 1 loss: 0.08067479729652405\n",
      "eopch: 12 step: 2 loss: 0.08162844181060791\n",
      "eopch: 12 step: 3 loss: 0.0793101042509079\n",
      "eopch: 12 step: 4 loss: 0.07743462920188904\n",
      "eopch: 12 step: 5 loss: 0.08148610591888428\n",
      "eopch: 12 step: 6 loss: 0.07864826917648315\n",
      "eopch: 12 step: 7 loss: 0.07933961600065231\n",
      "eopch: 12 step: 8 loss: 0.07481749355792999\n",
      "eopch: 12 step: 9 loss: 0.07458195090293884\n",
      "eopch: 12 step: 10 loss: 0.07769981026649475\n",
      "eopch: 12 step: 11 loss: 0.07609739899635315\n",
      "eopch: 12 step: 12 loss: 0.08472094684839249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 12 step: 13 loss: 0.07609691470861435\n",
      "eopch: 12 step: 14 loss: 0.07244406640529633\n",
      "eopch: 12 step: 15 loss: 0.08154202252626419\n",
      "eopch: 12 step: 16 loss: 0.07330348342657089\n",
      "eopch: 13 step: 1 loss: 0.07568284124135971\n",
      "eopch: 13 step: 2 loss: 0.07610709965229034\n",
      "eopch: 13 step: 3 loss: 0.07459302991628647\n",
      "eopch: 13 step: 4 loss: 0.07285891473293304\n",
      "eopch: 13 step: 5 loss: 0.0768188089132309\n",
      "eopch: 13 step: 6 loss: 0.07337299734354019\n",
      "eopch: 13 step: 7 loss: 0.07430561631917953\n",
      "eopch: 13 step: 8 loss: 0.06991912424564362\n",
      "eopch: 13 step: 9 loss: 0.0691470131278038\n",
      "eopch: 13 step: 10 loss: 0.07179301232099533\n",
      "eopch: 13 step: 11 loss: 0.07198887318372726\n",
      "eopch: 13 step: 12 loss: 0.07961997389793396\n",
      "eopch: 13 step: 13 loss: 0.07219628989696503\n",
      "eopch: 13 step: 14 loss: 0.06755445152521133\n",
      "eopch: 13 step: 15 loss: 0.07676813751459122\n",
      "eopch: 13 step: 16 loss: 0.06878890842199326\n",
      "eopch: 14 step: 1 loss: 0.0699026957154274\n",
      "eopch: 14 step: 2 loss: 0.07080702483654022\n",
      "eopch: 14 step: 3 loss: 0.06852111220359802\n",
      "eopch: 14 step: 4 loss: 0.06737008690834045\n",
      "eopch: 14 step: 5 loss: 0.07117883861064911\n",
      "eopch: 14 step: 6 loss: 0.06724293529987335\n",
      "eopch: 14 step: 7 loss: 0.0691070556640625\n",
      "eopch: 14 step: 8 loss: 0.06481383740901947\n",
      "eopch: 14 step: 9 loss: 0.06397052854299545\n",
      "eopch: 14 step: 10 loss: 0.06650170683860779\n",
      "eopch: 14 step: 11 loss: 0.06611441820859909\n",
      "eopch: 14 step: 12 loss: 0.07585948705673218\n",
      "eopch: 14 step: 13 loss: 0.06631709635257721\n",
      "eopch: 14 step: 14 loss: 0.061650630086660385\n",
      "eopch: 14 step: 15 loss: 0.07237107306718826\n",
      "eopch: 14 step: 16 loss: 0.06291117519140244\n",
      "eopch: 15 step: 1 loss: 0.06550915539264679\n",
      "eopch: 15 step: 2 loss: 0.06489099562168121\n",
      "eopch: 15 step: 3 loss: 0.0630565956234932\n",
      "eopch: 15 step: 4 loss: 0.06192818656563759\n",
      "eopch: 15 step: 5 loss: 0.06513795256614685\n",
      "eopch: 15 step: 6 loss: 0.06194503605365753\n",
      "eopch: 15 step: 7 loss: 0.06411972641944885\n",
      "eopch: 15 step: 8 loss: 0.059110719710588455\n",
      "eopch: 15 step: 9 loss: 0.05746287852525711\n",
      "eopch: 15 step: 10 loss: 0.060032498091459274\n",
      "eopch: 15 step: 11 loss: 0.06158709153532982\n",
      "eopch: 15 step: 12 loss: 0.07084579020738602\n",
      "eopch: 15 step: 13 loss: 0.060922786593437195\n",
      "eopch: 15 step: 14 loss: 0.055174246430397034\n",
      "eopch: 15 step: 15 loss: 0.06537581980228424\n",
      "eopch: 15 step: 16 loss: 0.05698772892355919\n",
      "eopch: 16 step: 1 loss: 0.06108975410461426\n",
      "eopch: 16 step: 2 loss: 0.05998145788908005\n",
      "eopch: 16 step: 3 loss: 0.057818084955215454\n",
      "eopch: 16 step: 4 loss: 0.05674547329545021\n",
      "eopch: 16 step: 5 loss: 0.06038198992609978\n",
      "eopch: 16 step: 6 loss: 0.05604394152760506\n",
      "eopch: 16 step: 7 loss: 0.05816579610109329\n",
      "eopch: 16 step: 8 loss: 0.05313508212566376\n",
      "eopch: 16 step: 9 loss: 0.053046222776174545\n",
      "eopch: 16 step: 10 loss: 0.05340449512004852\n",
      "eopch: 16 step: 11 loss: 0.05510839447379112\n",
      "eopch: 16 step: 12 loss: 0.06506053358316422\n",
      "eopch: 16 step: 13 loss: 0.056973859667778015\n",
      "eopch: 16 step: 14 loss: 0.05095391720533371\n",
      "eopch: 16 step: 15 loss: 0.05921235680580139\n",
      "eopch: 16 step: 16 loss: 0.05243048816919327\n",
      "eopch: 17 step: 1 loss: 0.05591731518507004\n",
      "eopch: 17 step: 2 loss: 0.05361776426434517\n",
      "eopch: 17 step: 3 loss: 0.05129734426736832\n",
      "eopch: 17 step: 4 loss: 0.05003803223371506\n",
      "eopch: 17 step: 5 loss: 0.05381356179714203\n",
      "eopch: 17 step: 6 loss: 0.05198384076356888\n",
      "eopch: 17 step: 7 loss: 0.05398985743522644\n",
      "eopch: 17 step: 8 loss: 0.047974929213523865\n",
      "eopch: 17 step: 9 loss: 0.04806006699800491\n",
      "eopch: 17 step: 10 loss: 0.04880921170115471\n",
      "eopch: 17 step: 11 loss: 0.05105128511786461\n",
      "eopch: 17 step: 12 loss: 0.060786716639995575\n",
      "eopch: 17 step: 13 loss: 0.05155985802412033\n",
      "eopch: 17 step: 14 loss: 0.045465223491191864\n",
      "eopch: 17 step: 15 loss: 0.055120259523391724\n",
      "eopch: 17 step: 16 loss: 0.047425806522369385\n",
      "eopch: 18 step: 1 loss: 0.05130098760128021\n",
      "eopch: 18 step: 2 loss: 0.050337426364421844\n",
      "eopch: 18 step: 3 loss: 0.04840748757123947\n",
      "eopch: 18 step: 4 loss: 0.04693770408630371\n",
      "eopch: 18 step: 5 loss: 0.04945923388004303\n",
      "eopch: 18 step: 6 loss: 0.04762286692857742\n",
      "eopch: 18 step: 7 loss: 0.04911032319068909\n",
      "eopch: 18 step: 8 loss: 0.04246492683887482\n",
      "eopch: 18 step: 9 loss: 0.041754528880119324\n",
      "eopch: 18 step: 10 loss: 0.04342799261212349\n",
      "eopch: 18 step: 11 loss: 0.04670652002096176\n",
      "eopch: 18 step: 12 loss: 0.05638108029961586\n",
      "eopch: 18 step: 13 loss: 0.046445176005363464\n",
      "eopch: 18 step: 14 loss: 0.041006188839673996\n",
      "eopch: 18 step: 15 loss: 0.0493803396821022\n",
      "eopch: 18 step: 16 loss: 0.043917130678892136\n",
      "eopch: 19 step: 1 loss: 0.0479210689663887\n",
      "eopch: 19 step: 2 loss: 0.044019415974617004\n",
      "eopch: 19 step: 3 loss: 0.04221014678478241\n",
      "eopch: 19 step: 4 loss: 0.04283088445663452\n",
      "eopch: 19 step: 5 loss: 0.045838434249162674\n",
      "eopch: 19 step: 6 loss: 0.04387941211462021\n",
      "eopch: 19 step: 7 loss: 0.04612909257411957\n",
      "eopch: 19 step: 8 loss: 0.04057416319847107\n",
      "eopch: 19 step: 9 loss: 0.038116566836833954\n",
      "eopch: 19 step: 10 loss: 0.038686614483594894\n",
      "eopch: 19 step: 11 loss: 0.042153194546699524\n",
      "eopch: 19 step: 12 loss: 0.05052734166383743\n",
      "eopch: 19 step: 13 loss: 0.042811084538698196\n",
      "eopch: 19 step: 14 loss: 0.03655441105365753\n",
      "eopch: 19 step: 15 loss: 0.04410228878259659\n",
      "eopch: 19 step: 16 loss: 0.03919238969683647\n",
      "eopch: 20 step: 1 loss: 0.04345165193080902\n",
      "eopch: 20 step: 2 loss: 0.04241880029439926\n",
      "eopch: 20 step: 3 loss: 0.03918948397040367\n",
      "eopch: 20 step: 4 loss: 0.03710730001330376\n",
      "eopch: 20 step: 5 loss: 0.03902572765946388\n",
      "eopch: 20 step: 6 loss: 0.040537167340517044\n",
      "eopch: 20 step: 7 loss: 0.04197390377521515\n",
      "eopch: 20 step: 8 loss: 0.03610334172844887\n",
      "eopch: 20 step: 9 loss: 0.034570470452308655\n",
      "eopch: 20 step: 10 loss: 0.03524758666753769\n",
      "eopch: 20 step: 11 loss: 0.03985416144132614\n",
      "eopch: 20 step: 12 loss: 0.04693843424320221\n",
      "eopch: 20 step: 13 loss: 0.03950534015893936\n",
      "eopch: 20 step: 14 loss: 0.03300320357084274\n",
      "eopch: 20 step: 15 loss: 0.04014415666460991\n",
      "eopch: 20 step: 16 loss: 0.03698679804801941\n",
      "eopch: 21 step: 1 loss: 0.03917246311903\n",
      "eopch: 21 step: 2 loss: 0.035925332456827164\n",
      "eopch: 21 step: 3 loss: 0.034506700932979584\n",
      "eopch: 21 step: 4 loss: 0.03391671180725098\n",
      "eopch: 21 step: 5 loss: 0.03548974171280861\n",
      "eopch: 21 step: 6 loss: 0.0369502454996109\n",
      "eopch: 21 step: 7 loss: 0.03805285692214966\n",
      "eopch: 21 step: 8 loss: 0.03037952072918415\n",
      "eopch: 21 step: 9 loss: 0.03095446527004242\n",
      "eopch: 21 step: 10 loss: 0.02980702742934227\n",
      "eopch: 21 step: 11 loss: 0.036003611981868744\n",
      "eopch: 21 step: 12 loss: 0.04249902814626694\n",
      "eopch: 21 step: 13 loss: 0.03616233542561531\n",
      "eopch: 21 step: 14 loss: 0.028407584875822067\n",
      "eopch: 21 step: 15 loss: 0.03405008465051651\n",
      "eopch: 21 step: 16 loss: 0.03316297009587288\n",
      "eopch: 22 step: 1 loss: 0.03622543811798096\n",
      "eopch: 22 step: 2 loss: 0.03466354310512543\n",
      "eopch: 22 step: 3 loss: 0.03312983363866806\n",
      "eopch: 22 step: 4 loss: 0.030007528141140938\n",
      "eopch: 22 step: 5 loss: 0.03061782941222191\n",
      "eopch: 22 step: 6 loss: 0.03482304513454437\n",
      "eopch: 22 step: 7 loss: 0.035244427621364594\n",
      "eopch: 22 step: 8 loss: 0.029071984812617302\n",
      "eopch: 22 step: 9 loss: 0.02678295411169529\n",
      "eopch: 22 step: 10 loss: 0.026730326935648918\n",
      "eopch: 22 step: 11 loss: 0.03320537507534027\n",
      "eopch: 22 step: 12 loss: 0.038872286677360535\n",
      "eopch: 22 step: 13 loss: 0.03431528061628342\n",
      "eopch: 22 step: 14 loss: 0.026048749685287476\n",
      "eopch: 22 step: 15 loss: 0.030187703669071198\n",
      "eopch: 22 step: 16 loss: 0.03168227896094322\n",
      "eopch: 23 step: 1 loss: 0.03252103179693222\n",
      "eopch: 23 step: 2 loss: 0.02814488112926483\n",
      "eopch: 23 step: 3 loss: 0.027143072336912155\n",
      "eopch: 23 step: 4 loss: 0.02709857188165188\n",
      "eopch: 23 step: 5 loss: 0.028091957792639732\n",
      "eopch: 23 step: 6 loss: 0.03093092143535614\n",
      "eopch: 23 step: 7 loss: 0.03049415908753872\n",
      "eopch: 23 step: 8 loss: 0.024456486105918884\n",
      "eopch: 23 step: 9 loss: 0.02458633854985237\n",
      "eopch: 23 step: 10 loss: 0.024418119341135025\n",
      "eopch: 23 step: 11 loss: 0.030513565987348557\n",
      "eopch: 23 step: 12 loss: 0.03570976480841637\n",
      "eopch: 23 step: 13 loss: 0.0308661051094532\n",
      "eopch: 23 step: 14 loss: 0.02128721959888935\n",
      "eopch: 23 step: 15 loss: 0.0269770585000515\n",
      "eopch: 23 step: 16 loss: 0.02873515896499157\n",
      "eopch: 24 step: 1 loss: 0.02969484031200409\n",
      "eopch: 24 step: 2 loss: 0.02749996818602085\n",
      "eopch: 24 step: 3 loss: 0.027024079114198685\n",
      "eopch: 24 step: 4 loss: 0.024088043719530106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 24 step: 5 loss: 0.02523714303970337\n",
      "eopch: 24 step: 6 loss: 0.028921063989400864\n",
      "eopch: 24 step: 7 loss: 0.0289878249168396\n",
      "eopch: 24 step: 8 loss: 0.023684242740273476\n",
      "eopch: 24 step: 9 loss: 0.021259788423776627\n",
      "eopch: 24 step: 10 loss: 0.020491696894168854\n",
      "eopch: 24 step: 11 loss: 0.02666321024298668\n",
      "eopch: 24 step: 12 loss: 0.0332554429769516\n",
      "eopch: 24 step: 13 loss: 0.029199030250310898\n",
      "eopch: 24 step: 14 loss: 0.019710037857294083\n",
      "eopch: 24 step: 15 loss: 0.023194190114736557\n",
      "eopch: 24 step: 16 loss: 0.027634531259536743\n",
      "eopch: 25 step: 1 loss: 0.027202405035495758\n",
      "eopch: 25 step: 2 loss: 0.023360878229141235\n",
      "eopch: 25 step: 3 loss: 0.022329919040203094\n",
      "eopch: 25 step: 4 loss: 0.021639620885252953\n",
      "eopch: 25 step: 5 loss: 0.021667974069714546\n",
      "eopch: 25 step: 6 loss: 0.027951551601290703\n",
      "eopch: 25 step: 7 loss: 0.025422852486371994\n",
      "eopch: 25 step: 8 loss: 0.019548222422599792\n",
      "eopch: 25 step: 9 loss: 0.01938430219888687\n",
      "eopch: 25 step: 10 loss: 0.019170571118593216\n",
      "eopch: 25 step: 11 loss: 0.024746214970946312\n",
      "eopch: 25 step: 12 loss: 0.030302856117486954\n",
      "eopch: 25 step: 13 loss: 0.026481399312615395\n",
      "eopch: 25 step: 14 loss: 0.016986507922410965\n",
      "eopch: 25 step: 15 loss: 0.02048460766673088\n",
      "eopch: 25 step: 16 loss: 0.02559763193130493\n",
      "eopch: 26 step: 1 loss: 0.024547351524233818\n",
      "eopch: 26 step: 2 loss: 0.02172652818262577\n",
      "eopch: 26 step: 3 loss: 0.02038201317191124\n",
      "eopch: 26 step: 4 loss: 0.019274568185210228\n",
      "eopch: 26 step: 5 loss: 0.019397078081965446\n",
      "eopch: 26 step: 6 loss: 0.025433748960494995\n",
      "eopch: 26 step: 7 loss: 0.022678282111883163\n",
      "eopch: 26 step: 8 loss: 0.017737826332449913\n",
      "eopch: 26 step: 9 loss: 0.01630001701414585\n",
      "eopch: 26 step: 10 loss: 0.015986258164048195\n",
      "eopch: 26 step: 11 loss: 0.022260572761297226\n",
      "eopch: 26 step: 12 loss: 0.02802647277712822\n",
      "eopch: 26 step: 13 loss: 0.025129025802016258\n",
      "eopch: 26 step: 14 loss: 0.014481652528047562\n",
      "eopch: 26 step: 15 loss: 0.01818579062819481\n",
      "eopch: 26 step: 16 loss: 0.02353665791451931\n",
      "eopch: 27 step: 1 loss: 0.02084023877978325\n",
      "eopch: 27 step: 2 loss: 0.01669929176568985\n",
      "eopch: 27 step: 3 loss: 0.01670910231769085\n",
      "eopch: 27 step: 4 loss: 0.016778431832790375\n",
      "eopch: 27 step: 5 loss: 0.016664236783981323\n",
      "eopch: 27 step: 6 loss: 0.023743879050016403\n",
      "eopch: 27 step: 7 loss: 0.020398488268256187\n",
      "eopch: 27 step: 8 loss: 0.014854601584374905\n",
      "eopch: 27 step: 9 loss: 0.015005323104560375\n",
      "eopch: 27 step: 10 loss: 0.01477544941008091\n",
      "eopch: 27 step: 11 loss: 0.020548582077026367\n",
      "eopch: 27 step: 12 loss: 0.02569659613072872\n",
      "eopch: 27 step: 13 loss: 0.02394097112119198\n",
      "eopch: 27 step: 14 loss: 0.012903152965009212\n",
      "eopch: 27 step: 15 loss: 0.015678487718105316\n",
      "eopch: 27 step: 16 loss: 0.022041264921426773\n",
      "eopch: 28 step: 1 loss: 0.019318290054798126\n",
      "eopch: 28 step: 2 loss: 0.01691134087741375\n",
      "eopch: 28 step: 3 loss: 0.014955652877688408\n",
      "eopch: 28 step: 4 loss: 0.015007071197032928\n",
      "eopch: 28 step: 5 loss: 0.014763211831450462\n",
      "eopch: 28 step: 6 loss: 0.021707404404878616\n",
      "eopch: 28 step: 7 loss: 0.019252516329288483\n",
      "eopch: 28 step: 8 loss: 0.015743743628263474\n",
      "eopch: 28 step: 9 loss: 0.01260423008352518\n",
      "eopch: 28 step: 10 loss: 0.012212292291224003\n",
      "eopch: 28 step: 11 loss: 0.018278146162629128\n",
      "eopch: 28 step: 12 loss: 0.023926906287670135\n",
      "eopch: 28 step: 13 loss: 0.02258322387933731\n",
      "eopch: 28 step: 14 loss: 0.011712908744812012\n",
      "eopch: 28 step: 15 loss: 0.01420507114380598\n",
      "eopch: 28 step: 16 loss: 0.02050558291375637\n",
      "eopch: 29 step: 1 loss: 0.01668778993189335\n",
      "eopch: 29 step: 2 loss: 0.013427844271063805\n",
      "eopch: 29 step: 3 loss: 0.015234919264912605\n",
      "eopch: 29 step: 4 loss: 0.01446928083896637\n",
      "eopch: 29 step: 5 loss: 0.01319260522723198\n",
      "eopch: 29 step: 6 loss: 0.020069457590579987\n",
      "eopch: 29 step: 7 loss: 0.016375690698623657\n",
      "eopch: 29 step: 8 loss: 0.011884424835443497\n",
      "eopch: 29 step: 9 loss: 0.015148010104894638\n",
      "eopch: 29 step: 10 loss: 0.01350168976932764\n",
      "eopch: 29 step: 11 loss: 0.01682472601532936\n",
      "eopch: 29 step: 12 loss: 0.022347163408994675\n",
      "eopch: 29 step: 13 loss: 0.021357398480176926\n",
      "eopch: 29 step: 14 loss: 0.010410347953438759\n",
      "eopch: 29 step: 15 loss: 0.012154712341725826\n",
      "eopch: 29 step: 16 loss: 0.01962227001786232\n",
      "eopch: 30 step: 1 loss: 0.018238985911011696\n",
      "eopch: 30 step: 2 loss: 0.01798773556947708\n",
      "eopch: 30 step: 3 loss: 0.012395238503813744\n",
      "eopch: 30 step: 4 loss: 0.012629115022718906\n",
      "eopch: 30 step: 5 loss: 0.011975416913628578\n",
      "eopch: 30 step: 6 loss: 0.018907766789197922\n",
      "eopch: 30 step: 7 loss: 0.018779315054416656\n",
      "eopch: 30 step: 8 loss: 0.01660071313381195\n",
      "eopch: 30 step: 9 loss: 0.010596031323075294\n",
      "eopch: 30 step: 10 loss: 0.01155532244592905\n",
      "eopch: 30 step: 11 loss: 0.015536768361926079\n",
      "eopch: 30 step: 12 loss: 0.022563360631465912\n",
      "eopch: 30 step: 13 loss: 0.020873617380857468\n",
      "eopch: 30 step: 14 loss: 0.009879209101200104\n",
      "eopch: 30 step: 15 loss: 0.01127571240067482\n",
      "eopch: 30 step: 16 loss: 0.018347134813666344\n",
      "eopch: 31 step: 1 loss: 0.014055509120225906\n",
      "eopch: 31 step: 2 loss: 0.011490372009575367\n",
      "eopch: 31 step: 3 loss: 0.01381021086126566\n",
      "eopch: 31 step: 4 loss: 0.014550386928021908\n",
      "eopch: 31 step: 5 loss: 0.013591216877102852\n",
      "eopch: 31 step: 6 loss: 0.0177694670855999\n",
      "eopch: 31 step: 7 loss: 0.013742515817284584\n",
      "eopch: 31 step: 8 loss: 0.00968375988304615\n",
      "eopch: 31 step: 9 loss: 0.016770929098129272\n",
      "eopch: 31 step: 10 loss: 0.017118673771619797\n",
      "eopch: 31 step: 11 loss: 0.015319336205720901\n",
      "eopch: 31 step: 12 loss: 0.021604441106319427\n",
      "eopch: 31 step: 13 loss: 0.019296761602163315\n",
      "eopch: 31 step: 14 loss: 0.009078135713934898\n",
      "eopch: 31 step: 15 loss: 0.010263343341648579\n",
      "eopch: 31 step: 16 loss: 0.01712377369403839\n",
      "eopch: 32 step: 1 loss: 0.016640206798911095\n",
      "eopch: 32 step: 2 loss: 0.018443500623106956\n",
      "eopch: 32 step: 3 loss: 0.011913708411157131\n",
      "eopch: 32 step: 4 loss: 0.010916150175035\n",
      "eopch: 32 step: 5 loss: 0.010143289342522621\n",
      "eopch: 32 step: 6 loss: 0.01753721944987774\n",
      "eopch: 32 step: 7 loss: 0.013839083723723888\n",
      "eopch: 32 step: 8 loss: 0.013670794665813446\n",
      "eopch: 32 step: 9 loss: 0.008338107727468014\n",
      "eopch: 32 step: 10 loss: 0.008638426661491394\n",
      "eopch: 32 step: 11 loss: 0.012890220619738102\n",
      "eopch: 32 step: 12 loss: 0.018666541203856468\n",
      "eopch: 32 step: 13 loss: 0.01805223524570465\n",
      "eopch: 32 step: 14 loss: 0.00891869142651558\n",
      "eopch: 32 step: 15 loss: 0.010852135717868805\n",
      "eopch: 32 step: 16 loss: 0.016192277893424034\n",
      "eopch: 33 step: 1 loss: 0.011955959722399712\n",
      "eopch: 33 step: 2 loss: 0.009474126622080803\n",
      "eopch: 33 step: 3 loss: 0.009716448374092579\n",
      "eopch: 33 step: 4 loss: 0.010572226718068123\n",
      "eopch: 33 step: 5 loss: 0.009938475675880909\n",
      "eopch: 33 step: 6 loss: 0.015359937213361263\n",
      "eopch: 33 step: 7 loss: 0.010259204544126987\n",
      "eopch: 33 step: 8 loss: 0.007698810659348965\n",
      "eopch: 33 step: 9 loss: 0.009288748726248741\n",
      "eopch: 33 step: 10 loss: 0.008117231540381908\n",
      "eopch: 33 step: 11 loss: 0.010901892557740211\n",
      "eopch: 33 step: 12 loss: 0.017322111874818802\n",
      "eopch: 33 step: 13 loss: 0.01636544242501259\n",
      "eopch: 33 step: 14 loss: 0.006935805082321167\n",
      "eopch: 33 step: 15 loss: 0.007342373486608267\n",
      "eopch: 33 step: 16 loss: 0.013392616994678974\n",
      "eopch: 34 step: 1 loss: 0.011015612632036209\n",
      "eopch: 34 step: 2 loss: 0.012877053581178188\n",
      "eopch: 34 step: 3 loss: 0.008409957401454449\n",
      "eopch: 34 step: 4 loss: 0.007811062969267368\n",
      "eopch: 34 step: 5 loss: 0.007731781806796789\n",
      "eopch: 34 step: 6 loss: 0.013340049423277378\n",
      "eopch: 34 step: 7 loss: 0.009608441032469273\n",
      "eopch: 34 step: 8 loss: 0.007826952263712883\n",
      "eopch: 34 step: 9 loss: 0.006910459138453007\n",
      "eopch: 34 step: 10 loss: 0.006212344393134117\n",
      "eopch: 34 step: 11 loss: 0.00979153998196125\n",
      "eopch: 34 step: 12 loss: 0.015354049392044544\n",
      "eopch: 34 step: 13 loss: 0.014401588588953018\n",
      "eopch: 34 step: 14 loss: 0.006191745400428772\n",
      "eopch: 34 step: 15 loss: 0.008355477824807167\n",
      "eopch: 34 step: 16 loss: 0.012074234895408154\n",
      "eopch: 35 step: 1 loss: 0.009157155640423298\n",
      "eopch: 35 step: 2 loss: 0.008837396278977394\n",
      "eopch: 35 step: 3 loss: 0.006842215079814196\n",
      "eopch: 35 step: 4 loss: 0.006904153153300285\n",
      "eopch: 35 step: 5 loss: 0.009367002174258232\n",
      "eopch: 35 step: 6 loss: 0.011571800336241722\n",
      "eopch: 35 step: 7 loss: 0.007699665613472462\n",
      "eopch: 35 step: 8 loss: 0.00618980685248971\n",
      "eopch: 35 step: 9 loss: 0.0067017776891589165\n",
      "eopch: 35 step: 10 loss: 0.005979631096124649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 35 step: 11 loss: 0.008180780336260796\n",
      "eopch: 35 step: 12 loss: 0.013734368607401848\n",
      "eopch: 35 step: 13 loss: 0.012884421274065971\n",
      "eopch: 35 step: 14 loss: 0.0053854756988584995\n",
      "eopch: 35 step: 15 loss: 0.006206156220287085\n",
      "eopch: 35 step: 16 loss: 0.010307284072041512\n",
      "eopch: 36 step: 1 loss: 0.007795714307576418\n",
      "eopch: 36 step: 2 loss: 0.009622598066926003\n",
      "eopch: 36 step: 3 loss: 0.013240208849310875\n",
      "eopch: 36 step: 4 loss: 0.007219728548079729\n",
      "eopch: 36 step: 5 loss: 0.005797611083835363\n",
      "eopch: 36 step: 6 loss: 0.00976509228348732\n",
      "eopch: 36 step: 7 loss: 0.0073542119935154915\n",
      "eopch: 36 step: 8 loss: 0.005884835496544838\n",
      "eopch: 36 step: 9 loss: 0.005733435042202473\n",
      "eopch: 36 step: 10 loss: 0.005198546685278416\n",
      "eopch: 36 step: 11 loss: 0.007992325350642204\n",
      "eopch: 36 step: 12 loss: 0.012474587187170982\n",
      "eopch: 36 step: 13 loss: 0.01274903304874897\n",
      "eopch: 36 step: 14 loss: 0.0052006058394908905\n",
      "eopch: 36 step: 15 loss: 0.006471272557973862\n",
      "eopch: 36 step: 16 loss: 0.009743391536176205\n",
      "eopch: 37 step: 1 loss: 0.007755031809210777\n",
      "eopch: 37 step: 2 loss: 0.009106090292334557\n",
      "eopch: 37 step: 3 loss: 0.006437188480049372\n",
      "eopch: 37 step: 4 loss: 0.006334947422146797\n",
      "eopch: 37 step: 5 loss: 0.008449098095297813\n",
      "eopch: 37 step: 6 loss: 0.009606482461094856\n",
      "eopch: 37 step: 7 loss: 0.006990884430706501\n",
      "eopch: 37 step: 8 loss: 0.006023409776389599\n",
      "eopch: 37 step: 9 loss: 0.005889600142836571\n",
      "eopch: 37 step: 10 loss: 0.005475688725709915\n",
      "eopch: 37 step: 11 loss: 0.007032792083919048\n",
      "eopch: 37 step: 12 loss: 0.011430643498897552\n",
      "eopch: 37 step: 13 loss: 0.011261502280831337\n",
      "eopch: 37 step: 14 loss: 0.004388787783682346\n",
      "eopch: 37 step: 15 loss: 0.00518946535885334\n",
      "eopch: 37 step: 16 loss: 0.008055517449975014\n",
      "eopch: 38 step: 1 loss: 0.0058223409578204155\n",
      "eopch: 38 step: 2 loss: 0.005830517038702965\n",
      "eopch: 38 step: 3 loss: 0.011527273803949356\n",
      "eopch: 38 step: 4 loss: 0.008808225393295288\n",
      "eopch: 38 step: 5 loss: 0.004944789223372936\n",
      "eopch: 38 step: 6 loss: 0.007769353687763214\n",
      "eopch: 38 step: 7 loss: 0.006067536771297455\n",
      "eopch: 38 step: 8 loss: 0.005208966787904501\n",
      "eopch: 38 step: 9 loss: 0.0054135555401444435\n",
      "eopch: 38 step: 10 loss: 0.004285743925720453\n",
      "eopch: 38 step: 11 loss: 0.006759245414286852\n",
      "eopch: 38 step: 12 loss: 0.01029860321432352\n",
      "eopch: 38 step: 13 loss: 0.010514017194509506\n",
      "eopch: 38 step: 14 loss: 0.004086724016815424\n",
      "eopch: 38 step: 15 loss: 0.0051562185399234295\n",
      "eopch: 38 step: 16 loss: 0.007166380528360605\n",
      "eopch: 39 step: 1 loss: 0.0069466233253479\n",
      "eopch: 39 step: 2 loss: 0.006765579804778099\n",
      "eopch: 39 step: 3 loss: 0.004843925125896931\n",
      "eopch: 39 step: 4 loss: 0.004650374874472618\n",
      "eopch: 39 step: 5 loss: 0.004978491924703121\n",
      "eopch: 39 step: 6 loss: 0.007507483474910259\n",
      "eopch: 39 step: 7 loss: 0.0063654575496912\n",
      "eopch: 39 step: 8 loss: 0.0070383548736572266\n",
      "eopch: 39 step: 9 loss: 0.005615352187305689\n",
      "eopch: 39 step: 10 loss: 0.004115513060241938\n",
      "eopch: 39 step: 11 loss: 0.005598642863333225\n",
      "eopch: 39 step: 12 loss: 0.008764242753386497\n",
      "eopch: 39 step: 13 loss: 0.009500857442617416\n",
      "eopch: 39 step: 14 loss: 0.0036683445796370506\n",
      "eopch: 39 step: 15 loss: 0.004412545822560787\n",
      "eopch: 39 step: 16 loss: 0.006466182414442301\n",
      "eopch: 40 step: 1 loss: 0.005143428221344948\n",
      "eopch: 40 step: 2 loss: 0.004405387211591005\n",
      "eopch: 40 step: 3 loss: 0.004899240098893642\n",
      "eopch: 40 step: 4 loss: 0.005182585213333368\n",
      "eopch: 40 step: 5 loss: 0.004459971562027931\n",
      "eopch: 40 step: 6 loss: 0.006669865921139717\n",
      "eopch: 40 step: 7 loss: 0.005141898058354855\n",
      "eopch: 40 step: 8 loss: 0.004023892804980278\n",
      "eopch: 40 step: 9 loss: 0.004511034116148949\n",
      "eopch: 40 step: 10 loss: 0.0038982557598501444\n",
      "eopch: 40 step: 11 loss: 0.007250547409057617\n",
      "eopch: 40 step: 12 loss: 0.009052624925971031\n",
      "eopch: 40 step: 13 loss: 0.008055314421653748\n",
      "eopch: 40 step: 14 loss: 0.0032671215012669563\n",
      "eopch: 40 step: 15 loss: 0.004387897439301014\n",
      "eopch: 40 step: 16 loss: 0.005961873568594456\n",
      "eopch: 41 step: 1 loss: 0.005524715408682823\n",
      "eopch: 41 step: 2 loss: 0.004262929782271385\n",
      "eopch: 41 step: 3 loss: 0.0037129269912838936\n",
      "eopch: 41 step: 4 loss: 0.003561197780072689\n",
      "eopch: 41 step: 5 loss: 0.0036820759996771812\n",
      "eopch: 41 step: 6 loss: 0.00564533518627286\n",
      "eopch: 41 step: 7 loss: 0.004750346764922142\n",
      "eopch: 41 step: 8 loss: 0.004882704000920057\n",
      "eopch: 41 step: 9 loss: 0.003806090448051691\n",
      "eopch: 41 step: 10 loss: 0.0038540789391845465\n",
      "eopch: 41 step: 11 loss: 0.0045661041513085365\n",
      "eopch: 41 step: 12 loss: 0.006464824080467224\n",
      "eopch: 41 step: 13 loss: 0.006462644785642624\n",
      "eopch: 41 step: 14 loss: 0.0030527818016707897\n",
      "eopch: 41 step: 15 loss: 0.003317530732601881\n",
      "eopch: 41 step: 16 loss: 0.004785040859133005\n",
      "eopch: 42 step: 1 loss: 0.0035047847777605057\n",
      "eopch: 42 step: 2 loss: 0.0034883415792137384\n",
      "eopch: 42 step: 3 loss: 0.003095962107181549\n",
      "eopch: 42 step: 4 loss: 0.0034222363028675318\n",
      "eopch: 42 step: 5 loss: 0.003851292422041297\n",
      "eopch: 42 step: 6 loss: 0.00512280035763979\n",
      "eopch: 42 step: 7 loss: 0.0034574707970023155\n",
      "eopch: 42 step: 8 loss: 0.0027735549956560135\n",
      "eopch: 42 step: 9 loss: 0.0029842806980013847\n",
      "eopch: 42 step: 10 loss: 0.00351917021907866\n",
      "eopch: 42 step: 11 loss: 0.007662125863134861\n",
      "eopch: 42 step: 12 loss: 0.006548516917973757\n",
      "eopch: 42 step: 13 loss: 0.006238173693418503\n",
      "eopch: 42 step: 14 loss: 0.002545049414038658\n",
      "eopch: 42 step: 15 loss: 0.0030053043738007545\n",
      "eopch: 42 step: 16 loss: 0.004587187897413969\n",
      "eopch: 43 step: 1 loss: 0.0036215779837220907\n",
      "eopch: 43 step: 2 loss: 0.003125531133264303\n",
      "eopch: 43 step: 3 loss: 0.0028268436435610056\n",
      "eopch: 43 step: 4 loss: 0.00296253664419055\n",
      "eopch: 43 step: 5 loss: 0.002981348428875208\n",
      "eopch: 43 step: 6 loss: 0.004290164448320866\n",
      "eopch: 43 step: 7 loss: 0.0038007255643606186\n",
      "eopch: 43 step: 8 loss: 0.0027825830038636923\n",
      "eopch: 43 step: 9 loss: 0.0027647826354950666\n",
      "eopch: 43 step: 10 loss: 0.003127522999420762\n",
      "eopch: 43 step: 11 loss: 0.0036453446373343468\n",
      "eopch: 43 step: 12 loss: 0.004817318171262741\n",
      "eopch: 43 step: 13 loss: 0.005681573413312435\n",
      "eopch: 43 step: 14 loss: 0.0021693692542612553\n",
      "eopch: 43 step: 15 loss: 0.0025184545665979385\n",
      "eopch: 43 step: 16 loss: 0.003977913875132799\n",
      "eopch: 44 step: 1 loss: 0.0028841434977948666\n",
      "eopch: 44 step: 2 loss: 0.0026344778016209602\n",
      "eopch: 44 step: 3 loss: 0.002502250485122204\n",
      "eopch: 44 step: 4 loss: 0.0025610271841287613\n",
      "eopch: 44 step: 5 loss: 0.002728548366576433\n",
      "eopch: 44 step: 6 loss: 0.003914263565093279\n",
      "eopch: 44 step: 7 loss: 0.002923500258475542\n",
      "eopch: 44 step: 8 loss: 0.002202278235927224\n",
      "eopch: 44 step: 9 loss: 0.0022096876055002213\n",
      "eopch: 44 step: 10 loss: 0.002168749924749136\n",
      "eopch: 44 step: 11 loss: 0.004181044176220894\n",
      "eopch: 44 step: 12 loss: 0.0045654140412807465\n",
      "eopch: 44 step: 13 loss: 0.004150169435888529\n",
      "eopch: 44 step: 14 loss: 0.0019544612150639296\n",
      "eopch: 44 step: 15 loss: 0.0022291545756161213\n",
      "eopch: 44 step: 16 loss: 0.0032766375225037336\n",
      "eopch: 45 step: 1 loss: 0.002535884501412511\n",
      "eopch: 45 step: 2 loss: 0.0022162175737321377\n",
      "eopch: 45 step: 3 loss: 0.002112257992848754\n",
      "eopch: 45 step: 4 loss: 0.002147011226043105\n",
      "eopch: 45 step: 5 loss: 0.0020650657825171947\n",
      "eopch: 45 step: 6 loss: 0.0031450255773961544\n",
      "eopch: 45 step: 7 loss: 0.0024591474793851376\n",
      "eopch: 45 step: 8 loss: 0.0018654554150998592\n",
      "eopch: 45 step: 9 loss: 0.0019210964674130082\n",
      "eopch: 45 step: 10 loss: 0.001826168387196958\n",
      "eopch: 45 step: 11 loss: 0.0024933195672929287\n",
      "eopch: 45 step: 12 loss: 0.0038881846703588963\n",
      "eopch: 45 step: 13 loss: 0.004628830123692751\n",
      "eopch: 45 step: 14 loss: 0.0018626698292791843\n",
      "eopch: 45 step: 15 loss: 0.0020501744002103806\n",
      "eopch: 45 step: 16 loss: 0.0030802451074123383\n",
      "eopch: 46 step: 1 loss: 0.0024131708778440952\n",
      "eopch: 46 step: 2 loss: 0.002036097226664424\n",
      "eopch: 46 step: 3 loss: 0.001866320613771677\n",
      "eopch: 46 step: 4 loss: 0.0019475306617096066\n",
      "eopch: 46 step: 5 loss: 0.0019199422094970942\n",
      "eopch: 46 step: 6 loss: 0.0028372416272759438\n",
      "eopch: 46 step: 7 loss: 0.0023588850162923336\n",
      "eopch: 46 step: 8 loss: 0.0017643457977101207\n",
      "eopch: 46 step: 9 loss: 0.001706632669083774\n",
      "eopch: 46 step: 10 loss: 0.001618110341951251\n",
      "eopch: 46 step: 11 loss: 0.002359963720664382\n",
      "eopch: 46 step: 12 loss: 0.0037760380655527115\n",
      "eopch: 46 step: 13 loss: 0.003509263973683119\n",
      "eopch: 46 step: 14 loss: 0.0016025039367377758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 46 step: 15 loss: 0.001740145729854703\n",
      "eopch: 46 step: 16 loss: 0.0026766450610011816\n",
      "eopch: 47 step: 1 loss: 0.0019442790653556585\n",
      "eopch: 47 step: 2 loss: 0.0017759962938725948\n",
      "eopch: 47 step: 3 loss: 0.0016953349113464355\n",
      "eopch: 47 step: 4 loss: 0.0018213969888165593\n",
      "eopch: 47 step: 5 loss: 0.0017774637090042233\n",
      "eopch: 47 step: 6 loss: 0.002698369324207306\n",
      "eopch: 47 step: 7 loss: 0.00231458549387753\n",
      "eopch: 47 step: 8 loss: 0.0015946337953209877\n",
      "eopch: 47 step: 9 loss: 0.001580846612341702\n",
      "eopch: 47 step: 10 loss: 0.0014905957505106926\n",
      "eopch: 47 step: 11 loss: 0.00220320513471961\n",
      "eopch: 47 step: 12 loss: 0.0033494934905320406\n",
      "eopch: 47 step: 13 loss: 0.004002728499472141\n",
      "eopch: 47 step: 14 loss: 0.001605217345058918\n",
      "eopch: 47 step: 15 loss: 0.0016963155940175056\n",
      "eopch: 47 step: 16 loss: 0.0025351555086672306\n",
      "eopch: 48 step: 1 loss: 0.0019157490460202098\n",
      "eopch: 48 step: 2 loss: 0.0016878676833584905\n",
      "eopch: 48 step: 3 loss: 0.0016096231993287802\n",
      "eopch: 48 step: 4 loss: 0.001693384605459869\n",
      "eopch: 48 step: 5 loss: 0.0016514561139047146\n",
      "eopch: 48 step: 6 loss: 0.002392152789980173\n",
      "eopch: 48 step: 7 loss: 0.0019509666599333286\n",
      "eopch: 48 step: 8 loss: 0.001477972138673067\n",
      "eopch: 48 step: 9 loss: 0.0014584450982511044\n",
      "eopch: 48 step: 10 loss: 0.0013900145422667265\n",
      "eopch: 48 step: 11 loss: 0.002085058018565178\n",
      "eopch: 48 step: 12 loss: 0.0031207925640046597\n",
      "eopch: 48 step: 13 loss: 0.0030700676143169403\n",
      "eopch: 48 step: 14 loss: 0.0014017877401784062\n",
      "eopch: 48 step: 15 loss: 0.001479493104852736\n",
      "eopch: 48 step: 16 loss: 0.0023346177767962217\n",
      "eopch: 49 step: 1 loss: 0.0017164910677820444\n",
      "eopch: 49 step: 2 loss: 0.00152108003385365\n",
      "eopch: 49 step: 3 loss: 0.0014468233566731215\n",
      "eopch: 49 step: 4 loss: 0.0015313331969082355\n",
      "eopch: 49 step: 5 loss: 0.001543319900520146\n",
      "eopch: 49 step: 6 loss: 0.002337293466553092\n",
      "eopch: 49 step: 7 loss: 0.001719208317808807\n",
      "eopch: 49 step: 8 loss: 0.001346489181742072\n",
      "eopch: 49 step: 9 loss: 0.001325790537521243\n",
      "eopch: 49 step: 10 loss: 0.0012742157559841871\n",
      "eopch: 49 step: 11 loss: 0.0018710294971242547\n",
      "eopch: 49 step: 12 loss: 0.002582283690571785\n",
      "eopch: 49 step: 13 loss: 0.0026097288355231285\n",
      "eopch: 49 step: 14 loss: 0.0012777871452271938\n",
      "eopch: 49 step: 15 loss: 0.0013530359137803316\n",
      "eopch: 49 step: 16 loss: 0.0020875369664281607\n",
      "eopch: 50 step: 1 loss: 0.0015607319073751569\n",
      "eopch: 50 step: 2 loss: 0.0013919002376496792\n",
      "eopch: 50 step: 3 loss: 0.0013304033782333136\n",
      "eopch: 50 step: 4 loss: 0.00135117769241333\n",
      "eopch: 50 step: 5 loss: 0.001332747284322977\n",
      "eopch: 50 step: 6 loss: 0.0019362082239240408\n",
      "eopch: 50 step: 7 loss: 0.0014997005928307772\n",
      "eopch: 50 step: 8 loss: 0.001202556537464261\n",
      "eopch: 50 step: 9 loss: 0.001209724578075111\n",
      "eopch: 50 step: 10 loss: 0.0011783691588789225\n",
      "eopch: 50 step: 11 loss: 0.00175994832534343\n",
      "eopch: 50 step: 12 loss: 0.0024841567501425743\n",
      "eopch: 50 step: 13 loss: 0.0025780568830668926\n",
      "eopch: 50 step: 14 loss: 0.0011489486787468195\n",
      "eopch: 50 step: 15 loss: 0.001249606953933835\n",
      "eopch: 50 step: 16 loss: 0.0019676778465509415\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    for step, i in enumerate(train_dl):\n",
    "        img, label_oh, label = i\n",
    "        img = Variable(img).cuda()\n",
    "        label_oh = Variable(label_oh.float()).cuda()\n",
    "        pred = model(img)\n",
    "        loss = loss_func(pred, label_oh)\n",
    "        optm.zero_grad()\n",
    "        loss.backward()\n",
    "        optm.step()\n",
    "        print('eopch:', epoch+1, 'step:', step+1, 'loss:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (img, label_oh, label) in enumerate(test_dl):\n",
    "    img = Variable(img).cuda()\n",
    "    pred = model(img)\n",
    "\n",
    "    c0 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[0:ALL_CHAR_SET_LEN])]\n",
    "    c1 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
    "    c2 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
    "    c3 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
    "    c4 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
    "    c = '%s%s%s%s%s' % (c0, c1, c2, c3, c4)\n",
    "\n",
    "    print('label:', label[0], 'pred:', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  #     .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_total= 69\n",
      "Lable : xfgxb Prediction Lable : xfdxb  : False\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8ff0972a2aaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#    .\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"False\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_images\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'{} predicted: {}  {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#     print('label:', label[0], 'pred:', c)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "test_correct = 0\n",
    "test_total = len(test_dl.dataset)\n",
    "num_images = 6\n",
    "print(\"test_total=\",test_total)\n",
    "\n",
    "for step, (img, label_oh, label) in enumerate(test_dl):\n",
    "    view_image = torchvision.utils.make_grid(img)\n",
    "    img = Variable(img).cuda()\n",
    "    pred = model(img)\n",
    "\n",
    "    c0 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[0:ALL_CHAR_SET_LEN])]\n",
    "    c1 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
    "    c2 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
    "    c3 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
    "    c4 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
    "    preds_label = '%s%s%s%s%s' % (c0, c1, c2, c3, c4)\n",
    "    \n",
    "    correct = \"\"\n",
    "    if label[0] == preds_label:\n",
    "        test_correct += 1\n",
    "        correct = \"True\"\n",
    "    else:\n",
    "        correct = \"False\"\n",
    "                \n",
    "    print(\"Lable : {} Prediction Lable : {}  : {}\".format(label[0], preds_label, correct))\n",
    "\n",
    "    #    .\n",
    "    if (correct == \"False\") and (num_images > step):\n",
    "        imshow(view_image, title='{} predicted: {}  {}'.format(i+1, preds_label, correct))\n",
    "\n",
    "#     print('label:', label[0], 'pred:', c)\n",
    "print(f'Test Accuracy: {(test_correct/test_total):.5f} ' +  f'({test_correct}/{test_total})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RPA_env",
   "language": "python",
   "name": "aa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
