{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_DIR = 'images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of images using OpenCV\n",
    "\n",
    "We will write basic functions for different preprocessing methods \n",
    "- grayscaling\n",
    "- thresholding\n",
    "- dilating\n",
    "- eroding\n",
    "- opening\n",
    "- canny edge detection\n",
    "- noise removal\n",
    "- deskwing\n",
    "- template matching. \n",
    "\n",
    "Different methods can come in handy with different kinds of images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "#template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original image\n",
    "\n",
    "image = cv2.imread(IMG_DIR + 'aurebesh.jpg')\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "plt.imshow(rgb_img)\n",
    "plt.title('AUREBESH ORIGINAL IMAGE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess image \n",
    "\n",
    "gray = get_grayscale(image)\n",
    "thresh = thresholding(gray)\n",
    "opening = opening(gray)\n",
    "canny = canny(gray)\n",
    "images = {'gray': gray, \n",
    "          'thresh': thresh, \n",
    "          'opening': opening, \n",
    "          'canny': canny}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images after preprocessing\n",
    "\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "ax = []\n",
    "\n",
    "rows = 2\n",
    "columns = 2\n",
    "keys = list(images.keys())\n",
    "for i in range(rows*columns):\n",
    "    ax.append( fig.add_subplot(rows, columns, i+1) )\n",
    "    ax[-1].set_title('AUREBESH - ' + keys[i]) \n",
    "    plt.imshow(images[keys[i]], cmap='gray')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OCR output using Pytesseract\n",
    "\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "print('-----------------------------------------')\n",
    "print('TESSERACT OUTPUT --> ORIGINAL IMAGE')\n",
    "print('-----------------------------------------')\n",
    "print(pytesseract.image_to_string(image, config=custom_config))\n",
    "print('\\n-----------------------------------------')\n",
    "print('TESSERACT OUTPUT --> THRESHOLDED IMAGE')\n",
    "print('-----------------------------------------')\n",
    "print(pytesseract.image_to_string(image, config=custom_config))\n",
    "print('\\n-----------------------------------------')\n",
    "print('TESSERACT OUTPUT --> OPENED IMAGE')\n",
    "print('-----------------------------------------')\n",
    "print(pytesseract.image_to_string(image, config=custom_config))\n",
    "print('\\n-----------------------------------------')\n",
    "print('TESSERACT OUTPUT --> CANNY EDGE IMAGE')\n",
    "print('-----------------------------------------')\n",
    "print(pytesseract.image_to_string(image, config=custom_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding box information using Pytesseract\n",
    "\n",
    "While running and image through the tesseract OCR engine, pytesseract allows you to get bounding box imformation \n",
    "- on a character level\n",
    "- on a word level\n",
    "- based on a regex template\n",
    "\n",
    "We will see how to obtain both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original image\n",
    "\n",
    "image = cv2.imread(IMG_DIR + 'invoice-sample.jpg')\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(rgb_img)\n",
    "plt.title('SAMPLE INVOICE IMAGE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot character boxes on image using pytesseract.image_to_boxes() function\n",
    "\n",
    "image = cv2.imread(IMG_DIR + 'invoice-sample.jpg')\n",
    "h, w, c = image.shape\n",
    "boxes = pytesseract.image_to_boxes(image) \n",
    "for b in boxes.splitlines():\n",
    "    b = b.split(' ')\n",
    "    image = cv2.rectangle(image, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
    "\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(rgb_img)\n",
    "plt.title('SAMPLE INVOICE WITH CHARACTER LEVEL BOXES')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot word boxes on image using pytesseract.image_to_data() function\n",
    "\n",
    "image = cv2.imread(IMG_DIR + 'invoice-sample.jpg')\n",
    "d = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
    "print('DATA KEYS: \\n', d.keys())\n",
    "\n",
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    # condition to only pick boxes with a confidence > 60%\n",
    "    if int(d['conf'][i]) > 60:\n",
    "        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(rgb_img)\n",
    "plt.title('SAMPLE INVOICE WITH WORD LEVEL BOXES')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxes around text that matches a certain regex template\n",
    "# In this example we will extract the date from the sample invoice\n",
    "\n",
    "image = cv2.imread(IMG_DIR + 'invoice-sample.jpg')\n",
    "date_pattern = '^(0[1-9]|[12][0-9]|3[01])/(0[1-9]|1[012])/(19|20)\\d\\d$'\n",
    "\n",
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    if int(d['conf'][i]) > 60:\n",
    "        if re.match(date_pattern, d['text'][i]):\n",
    "            (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "            image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(rgb_img)\n",
    "plt.title('SAMPLE INVOICE WITH BOXES FOR DATES')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page Segmentation Modes\n",
    "\n",
    "There are several ways a page of text can be analysed. The tesseract api provides several page segmentation modes if you want to run OCR on only a small region or in different orientations, etc.\n",
    "\n",
    "Here's a list of the supported page segmentation modes by tesseract -\n",
    "\n",
    "0    Orientation and script detection (OSD) only.  \n",
    "1    Automatic page segmentation with OSD.  \n",
    "2    Automatic page segmentation, but no OSD, or OCR.  \n",
    "3    Fully automatic page segmentation, but no OSD. (Default)  \n",
    "4    Assume a single column of text of variable sizes.  \n",
    "5    Assume a single uniform block of vertically aligned text.  \n",
    "6    Assume a single uniform block of text.  \n",
    "7    Treat the image as a single text line.  \n",
    "8    Treat the image as a single word.  \n",
    "9    Treat the image as a single word in a circle.  \n",
    "10    Treat the image as a single character.  \n",
    "11    Sparse text. Find as much text as possible in no particular order.  \n",
    "12    Sparse text with OSD.  \n",
    "13    Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific.  \n",
    "\n",
    "To change your page segmentation mode, change the ```--psm``` argument in your custom config string to any of the above mentioned mode codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect orientation and script\n",
    "\n",
    "You can detect the orientation of text in your image and also the script in which it is written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original image\n",
    "\n",
    "image = cv2.imread(IMG_DIR + 'hitchhikers-rotated.png')\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(rgb_img)\n",
    "plt.title('HITCHHIKERS - ROTATED')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get angle and script\n",
    "\n",
    "osd = pytesseract.image_to_osd(image)\n",
    "angle = re.search('(?<=Rotate: )\\d+', osd).group(0)\n",
    "script = re.search('(?<=Script: )\\w+', osd).group(0)\n",
    "print(\"angle: \", angle)\n",
    "print(\"script: \", script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around with the config\n",
    "\n",
    "By making minor changes in the config file you can \n",
    "- specify language\n",
    "- detect only digits\n",
    "- whitelist characters\n",
    "- blacklist characters\n",
    "- work with multiple languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original image\n",
    "\n",
    "image = cv2.imread(IMG_DIR + 'digits-task.jpg')\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "plt.imshow(rgb_img)\n",
    "plt.title('SAMPLE TABLE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tesseract output with english language sepcified\n",
    "\n",
    "custom_config = r'-l eng --oem 3 --psm 6'\n",
    "print(pytesseract.image_to_string(image, config=custom_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output with outputbase digits\n",
    "\n",
    "custom_config = r'--oem 3 --psm 6 outputbase digits'\n",
    "print(pytesseract.image_to_string(image, config=custom_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output with a whitelist of characters (here, we have used all the lowercase characters from a to z only)\n",
    "\n",
    "custom_config = r'-c tessedit_char_whitelist=abcdefghijklmnopqrstuvwxyz --psm 6'\n",
    "print(pytesseract.image_to_string(image, config=custom_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output without the blacklisted characters (here, we have removed all digits)\n",
    "\n",
    "custom_config = r'-c tessedit_char_blacklist=0123456789 --psm 6'\n",
    "print(pytesseract.image_to_string(image, config=custom_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with multiple languages\n",
    "\n",
    "# Plot original image\n",
    "\n",
    "image = cv2.imread(IMG_DIR + 'greek-thai.png')\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "plt.figure(figsize=(8,16))\n",
    "plt.imshow(rgb_img, cmap = 'gray')\n",
    "plt.title('MULTIPLE LANGUAGE IMAGE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output with only english language specified\n",
    "\n",
    "custom_config = r'-l eng --oem 3 --psm 6'\n",
    "print(pytesseract.image_to_string(image, config=custom_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output with all languages specified\n",
    "\n",
    "custom_config = r'-l grc+tha+eng --oem 3 --psm 6'\n",
    "print(pytesseract.image_to_string(image, config=custom_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
